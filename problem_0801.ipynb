{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "problem_0801.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meriem-belkacemi/Test-SIC/blob/main/problem_0801.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsxL_e2JnusZ"
      },
      "source": [
        "## Quiz #0801"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGLZR7ZFnusi"
      },
      "source": [
        "### \"Text Classification with Keras\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9sECm6xnusk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15a31efc-5213-4068-a66c-b526d8631131"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import os\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.datasets import load_files\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, SimpleRNN, LSTM, Embedding\n",
        "#from keras.utils import to_categorical\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.preprocessing import sequence\n",
        "#from keras.optimizers import Adam, RMSprop, SGD\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "#nltk.download('stopwords')\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import seaborn as sns"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PDiT-Kjnusm"
      },
      "source": [
        "#### Answer the following question by providing Python code:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5MLkOq5nusn"
      },
      "source": [
        "1). Read in the movie review data from Cornell CS department. Carry out the EDA. <br>\n",
        "- The data can be found [here](https://www.cs.cornell.edu/people/pabo/movie-review-data). <br>\n",
        "- Download the “polarity dataset” and unzip. <br>\n",
        "- Under the \"txt_sentoken” folder, there are “pos” and “neg\" subfolders. <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWFGNFxinuso",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36bdac56-4ac0-4796-d9fd-e1768da2ccac"
      },
      "source": [
        "!wget https://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz\n"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-02 12:59:24--  https://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz\n",
            "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.36\n",
            "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3127238 (3.0M) [application/x-gzip]\n",
            "Saving to: ‘review_polarity.tar.gz.9’\n",
            "\n",
            "review_polarity.tar 100%[===================>]   2.98M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-09-02 12:59:24 (24.1 MB/s) - ‘review_polarity.tar.gz.9’ saved [3127238/3127238]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "940gVb6o8FdL"
      },
      "source": [
        "!tar xvzf review_polarity.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ydn4vg2Qnusp"
      },
      "source": [
        "2). Carry out the data preprocessing: <br>\n",
        "- Cleaning.\n",
        "- Stopword removal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSYaAnxJnusr"
      },
      "source": [
        "# Specify the folder and read in the subfolders.\n",
        "reviews = load_files('txt_sentoken/')\n",
        "my_docs, y = reviews.data, reviews.target"
      ],
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqeV0fsd8dsH",
        "outputId": "4aea395f-5149-472f-fb04-1c50c632887c"
      },
      "source": [
        "len(my_docs)"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fo_sI-5X8dzm",
        "outputId": "8cc8e049-539f-4985-c6eb-04e39206c75d"
      },
      "source": [
        "np.unique(y, return_counts=True)"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([1000, 1000]))"
            ]
          },
          "metadata": {},
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "ezz-eMhZkS4n",
        "outputId": "2c1b807f-b3c7-4207-fe6f-8b13d3a19a23"
      },
      "source": [
        "# Visualize the response variable.\n",
        "sns.countplot(y).set_title(\"Frequency Table\")\n",
        "plt.show()"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qscQrKFTkAr",
        "outputId": "281a69de-9e9d-4734-af11-b16fd2791b96"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stopwords = stopwords.words('english')\n",
        "# Adding custom stop-words\n",
        "stopwords.extend(['www','http','utc'])\n",
        "stopwords = set(stopwords)"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwlmPo_jTmhU"
      },
      "source": [
        "modified = [x.decode('utf-8') for x in my_docs]\n"
      ],
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p15hgjZ9Tmja"
      },
      "source": [
        "#Cleaning \n",
        "for i in range(len(modified)) : \n",
        "  # remove special characters/symbols\n",
        "  modified[i] = re.sub(r\"\\n\", \" \", modified[i]) \n",
        "  modified[i] = re.sub(\"[\\<\\[].*?[\\>\\]]\", \" \", modified[i])\n",
        "  #convert text to lower-case\n",
        "  modified[i] = modified[i].lower()\n",
        "  #retain only alphabets\n",
        "  modified[i] = re.sub(r\"[^a-z ]\", \" \", modified[i])\n",
        "  #remove words less than 3 characters\n",
        "  modified[i] = re.sub(r\"\\b\\w{1,3}\\b\", \" \",modified[i])"
      ],
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gey50OrGTmnW"
      },
      "source": [
        "#Stopword removal\n",
        "for i in range(len(modified)) : \n",
        "  modified[i] = \" \".join([x for x in modified[i].split() if x not in stopwords])"
      ],
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3kEyz1lTsu7"
      },
      "source": [
        "corpus = modified\n"
      ],
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-OgF_1knuss"
      },
      "source": [
        "[texte du lien](https://)3). Carry out label encoding by integers (required form by Keras):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYkJ91Ttnust"
      },
      "source": [
        "# Make a dictionary with the top words.\n",
        "n_words = 2000  \n",
        "words = []\n",
        "for i in range(len(corpus)):\n",
        "    words += nltk.word_tokenize(corpus[i])\n",
        "top_words = pd.Series(words).value_counts().index\n",
        "top_words = top_words[0:n_words]                     # Apply a limitation.\n",
        "my_dict = {}\n",
        "my_dict_inv = {}\n",
        "for i in range(len(top_words)):\n",
        "    my_dict_inv[i] = top_words[i]                    \n",
        "    my_dict[top_words[i]] = i"
      ],
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnHCdPVTpX53"
      },
      "source": [
        "# Convert the corpus into the label encoded form.\n",
        "corpus_int =[]\n",
        "for i in range(len(corpus)):\n",
        "    words = nltk.word_tokenize(corpus[i])\n",
        "    words2int = []\n",
        "    for x in words:\n",
        "        if x in my_dict:\n",
        "            words2int += [my_dict[x]]\n",
        "    corpus_int.append(words2int)"
      ],
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNEnRmd9nusu"
      },
      "source": [
        "4). Prepare the data for AI: <br>\n",
        "- Apply the padding.\n",
        "- Split the data into training and testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwbC4KvRnusv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bfbd3f4-a4ff-462f-c6b1-472a540f3406"
      },
      "source": [
        "X = np.array(corpus_int)\n",
        "y = np.array(y)"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMNTLBDuoJu4"
      },
      "source": [
        "# Padding: newswire lengths are uniformly matched to maxlen.\n",
        "X = sequence.pad_sequences(X, maxlen = 100)\n",
        "# y is already binary. Thus, there is no need to covert to the one-hot-encoding scheme."
      ],
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfnO5zW4oM4r"
      },
      "source": [
        "#split the data into training and testing\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.4)"
      ],
      "execution_count": 285,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4-D35LFRnxa",
        "outputId": "5a28ad49-1c15-474e-8d67-f35b5a7fd35d"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1200, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 286
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bkm3cuCKRpX8",
        "outputId": "dc04d5d4-69fa-4aad-976c-5fa158cccd11"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1200,)"
            ]
          },
          "metadata": {},
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GE0eoRURvgH",
        "outputId": "4ce766c0-787a-4048-c222-ad135efe5087"
      },
      "source": [
        "n_words\n"
      ],
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 288
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtHW6J1unusv"
      },
      "source": [
        "5). Define the AI model (Embedding + LSTM):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezoNRvm9nusw"
      },
      "source": [
        "n_neurons = 100                    # Neurons within each memory cell.\n",
        "n_input = 500                     # Dimension of the embeding space. "
      ],
      "execution_count": 289,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r6EBhLTonps"
      },
      "source": [
        "my_model = Sequential()\n"
      ],
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy5NX6Kih2p-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7a5da9b-7706-4872-c98f-4332769f954a"
      },
      "source": [
        "my_model.add(Embedding(n_words, n_input, input_length=n_neurons))\n",
        "my_model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "my_model.add(Dense(1, activation='sigmoid'))\n",
        "print(my_model.summary())"
      ],
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_12 (Embedding)     (None, 100, 500)          1000000   \n",
            "_________________________________________________________________\n",
            "lstm_12 (LSTM)               (None, 100)               240400    \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 1,240,501\n",
            "Trainable params: 1,240,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tw-fUxvnusx"
      },
      "source": [
        "6). Define the optimizer and compile the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SthDq7unusx"
      },
      "source": [
        "n_epochs = 15                      # Number of epochs.\n",
        "batch_size = 100                    # Size of each batch.\n",
        "learn_rate = 0.0001 "
      ],
      "execution_count": 292,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2OaiwlZh9zU"
      },
      "source": [
        "opt = Adam(learning_rate=learn_rate)\n",
        "my_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": 293,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1kSE53Gnusy"
      },
      "source": [
        "7). Train the model and visualize the summary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bds7DuTSnusy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f6a40fa-23aa-4be6-df96-24646855841a"
      },
      "source": [
        "history = my_model.fit(X_train, y_train, epochs=n_epochs, batch_size=batch_size,validation_split=0.1)#,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "11/11 [==============================] - 13s 926ms/step - loss: 0.0000e+00 - accuracy: 0.5037 - val_loss: 0.0000e+00 - val_accuracy: 0.4500\n",
            "Epoch 2/15\n",
            "11/11 [==============================] - 10s 883ms/step - loss: 0.0000e+00 - accuracy: 0.4907 - val_loss: 0.0000e+00 - val_accuracy: 0.4500\n",
            "Epoch 3/15\n",
            "11/11 [==============================] - 10s 881ms/step - loss: 0.0000e+00 - accuracy: 0.4861 - val_loss: 0.0000e+00 - val_accuracy: 0.4500\n",
            "Epoch 4/15\n",
            "11/11 [==============================] - 10s 879ms/step - loss: 0.0000e+00 - accuracy: 0.4861 - val_loss: 0.0000e+00 - val_accuracy: 0.4500\n",
            "Epoch 5/15\n",
            "11/11 [==============================] - 10s 883ms/step - loss: 0.0000e+00 - accuracy: 0.4861 - val_loss: 0.0000e+00 - val_accuracy: 0.4500\n",
            "Epoch 6/15\n",
            "11/11 [==============================] - 10s 882ms/step - loss: 0.0000e+00 - accuracy: 0.4861 - val_loss: 0.0000e+00 - val_accuracy: 0.4500\n",
            "Epoch 7/15\n",
            "11/11 [==============================] - 10s 880ms/step - loss: 0.0000e+00 - accuracy: 0.4861 - val_loss: 0.0000e+00 - val_accuracy: 0.4500\n",
            "Epoch 8/15\n",
            "11/11 [==============================] - 10s 890ms/step - loss: 0.0000e+00 - accuracy: 0.4861 - val_loss: 0.0000e+00 - val_accuracy: 0.4500\n",
            "Epoch 9/15\n",
            "11/11 [==============================] - 10s 889ms/step - loss: 0.0000e+00 - accuracy: 0.4861 - val_loss: 0.0000e+00 - val_accuracy: 0.4500\n",
            "Epoch 10/15\n",
            "11/11 [==============================] - 10s 884ms/step - loss: 0.0000e+00 - accuracy: 0.4861 - val_loss: 0.0000e+00 - val_accuracy: 0.4500\n",
            "Epoch 11/15\n",
            "11/11 [==============================] - 10s 884ms/step - loss: 0.0000e+00 - accuracy: 0.4861 - val_loss: 0.0000e+00 - val_accuracy: 0.4500\n",
            "Epoch 12/15\n",
            " 1/11 [=>............................] - ETA: 8s - loss: 0.0000e+00 - accuracy: 0.5000"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Yw9Eh_5nusy"
      },
      "source": [
        "8). Display the test result (accuracy):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ypva7wC6nusz"
      },
      "source": [
        "score = my_model.evaluate(X_test,y_test)\n",
        "print('Test set accuracy: {:0.2f}'.format(score[1]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}